{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('packagefordeployment/tokenizer0421.json') as f:\n",
    "    data = json.load(f)\n",
    "    ntokenizer = tf.keras.preprocessing.text.tokenizer_from_json(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretrainedmodel = tf.keras.models.load_model('sentimentdetectmodel.h5')\n",
    "pretrainedmodel = tf.keras.models.load_model('pretrainedmodel/sentimentdetectmodel0421.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9891399 ],\n",
       "       [0.9305    ],\n",
       "       [0.00625599],\n",
       "       [0.01510814],\n",
       "       [0.02991026],\n",
       "       [0.83468324],\n",
       "       [0.882621  ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testsentences = ['it was very good', 'i love my family', 'it was not very good'\n",
    "                 ,'Go with something that is better quality than this one'\n",
    "                 ,'i do not love ui work', ' i adore you', 'i luv you'\n",
    "                ]\n",
    "testsequences = ntokenizer.texts_to_sequences(testsentences)\n",
    "testpadded = pad_sequences(testsequences, maxlen=40)\n",
    "answer = pretrainedmodel.predict(testpadded)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def run(data):\n",
    "    try:\n",
    "        data = json.loads(data)\n",
    "        sentences = data['sentences']\n",
    "\n",
    "        testsequences = ntokenizer.texts_to_sequences(sentences)\n",
    "        testpadded = pad_sequences(testsequences, maxlen=40)\n",
    "        answer = pretrainedmodel.predict(testpadded)\n",
    "        answer = answer.reshape(len(sentences))\n",
    "        answer = np.array(answer, dtype=np.str)\n",
    "        #print(answer)\n",
    "        #res = dict(zip(sentences, answer)) \n",
    "        #print(res)\n",
    "        answer = list(answer)\n",
    "        \n",
    "        #result = {\"sentiment\":str(answer[0])}\n",
    "        return json.dumps(answer)\n",
    "        \n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"0.9891399\", \"0.9305\", \"0.00625599\", \"0.015108142\", \"0.02991026\", \"0.83468324\", \"0.882621\"]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {}\n",
    "mydict['sentences'] = testsentences\n",
    "run(json.dumps(mydict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def run(inputdata):\n",
    "    try:\n",
    "        data = json.loads(inputdata)\n",
    "        sentences = data['sentences']\n",
    "        inputdf = pd.DataFrame(sentences,columns=['inputdata'])\n",
    "        #print(inputdf)\n",
    "        testsequences = ntokenizer.texts_to_sequences(sentences)\n",
    "        testpadded = pad_sequences(testsequences, maxlen=40)\n",
    "        answer = pretrainedmodel.predict(testpadded)\n",
    "        answerdf = pd.DataFrame(answer, columns=['result'])\n",
    "       \n",
    "        #print(answerdf)\n",
    "        finalans = inputdf.join(answerdf)\n",
    "        finalans.index = finalans['inputdata']\n",
    "        finalans = finalans.drop(columns=['inputdata'])\n",
    "        #print(finalans)\n",
    "        #result = {\"sentiment\":str(answer[0])}\n",
    "        return json.dumps(finalans.to_dict())\n",
    "        \n",
    "        #return data +\n",
    "        # You can return any data type, as long as it is JSON serializable.\n",
    "\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"sentences\": [\"this is good\", \"this is very good\", \"i am very happy\", \"Go with something that is better quality than this one\"]}\n",
      "{\"result\": {\"this is good\": 0.9836187958717346, \"this is very good\": 0.994709849357605, \"i am very happy\": 0.9907805323600769, \"Go with something that is better quality than this one\": 0.015108142048120499}}\n"
     ]
    }
   ],
   "source": [
    "myobj = ['this is good', 'this is very good', 'i am very happy','Go with something that is better quality than this one']\n",
    "mydict = {}\n",
    "mydict['sentences'] = myobj\n",
    "print(json.dumps(mydict))\n",
    "result = run(json.dumps(mydict))\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "1.0.3\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 40, 100)           108335700 \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 40, 128)           84480     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                41216     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 108,465,621\n",
      "Trainable params: 129,921\n",
      "Non-trainable params: 108,335,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrainedmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
